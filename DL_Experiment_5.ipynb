{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Tanmayee Das\n",
        "##25/AFI/27\n"
      ],
      "metadata": {
        "id": "hVPu_Edg77I4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nauLo5Ep0Do0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(\"/content/poems-100.csv\")\n",
        "\n",
        "# Ignore first row and extract poems\n",
        "poems = df.iloc[1:, 0].astype(str).tolist()\n",
        "\n",
        "# Combine all poems into one text corpus\n",
        "text_data = \" \".join(poems).lower()\n",
        "\n",
        "print(\"Number of poems:\", len(poems))\n",
        "print(\"Sample text:\\n\", text_data[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDoDkgA30Iqe",
        "outputId": "daef78d6-7d17-4c6b-e3f5-c4e049590148"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of poems: 99\n",
            "Sample text:\n",
            " the rose is red,\n",
            "the violet's blue,\n",
            "sugar is sweet,\n",
            "and so are you. how do i love thee? let me count the ways.\n",
            "i love thee to the depth and breadth and height\n",
            "my soul can reach, when feeling out of sight\n",
            "for the ends of being and ideal grace.\n",
            "i love thee to the level of every day's\n",
            "most quiet need, by sun and candle-light.\n",
            "i love thee freely, as men strive for right.\n",
            "i love thee purely, as they turn from praise.\n",
            "i love thee with the passion put to use\n",
            "in my old griefs, and with my childhood's fa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple whitespace tokenization\n",
        "tokens = text_data.split()\n",
        "\n",
        "# Build vocabulary\n",
        "word_counts = Counter(tokens)\n",
        "vocab = sorted(word_counts.keys())\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Word to index mapping\n",
        "word2idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx2word = {i: word for word, i in word2idx.items()}\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"Sample vocab words:\", vocab[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zXusK_0IoE",
        "outputId": "e55b9f05-ac5c-4ea2-c361-fb182fd3cd3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6965\n",
            "Sample vocab words: ['\"he', '\"most', '\"oh,', \"'greatly\", \"'neath\", \"'our\", \"'s\", \"'tis\", \"'twas\", \"'twere\", \"'twill\", \"('tis\", '(1)', '(and', '(as', '(behind', '(come', '(even', '(floating', '(for']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        h = np.zeros((self.hidden_size, 1))\n",
        "        outputs = []\n",
        "\n",
        "        for x in inputs:\n",
        "            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)\n",
        "            y = np.dot(self.Why, h) + self.by\n",
        "            outputs.append(y)\n",
        "\n",
        "        return outputs, h"
      ],
      "metadata": {
        "id": "vXRq_pYU0IlW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "\n",
        "def create_sequences(tokens, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(tokens) - seq_length):\n",
        "        seq = tokens[i:i+seq_length]\n",
        "        target = tokens[i+seq_length]\n",
        "        sequences.append((seq, target))\n",
        "    return sequences\n",
        "\n",
        "sequences = create_sequences(tokens, sequence_length)\n",
        "print(\"Total sequences:\", len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDpgvoBe0Ii0",
        "outputId": "dc7a4ff2-1f41-4547-e8cc-3f0ce799a233"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences: 24623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(word, vocab_size):\n",
        "    vec = np.zeros(vocab_size)\n",
        "    vec[word2idx[word]] = 1\n",
        "    return vec"
      ],
      "metadata": {
        "id": "6AO_I5pJ0Igi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "\n",
        "        x = [one_hot_encode(word, vocab_size) for word in seq]\n",
        "        x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "        y = torch.tensor(word2idx[target], dtype=torch.long)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "dataset_onehot = OneHotDataset(sequences)\n",
        "loader_onehot = torch.utils.data.DataLoader(dataset_onehot, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "FK99dXZT0IeB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OneHot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN_OneHot, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "f1qGNPXG0Ib0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQmm4Psm4GAL",
        "outputId": "2d4f17a1-2344-4797-fd39-5e29f09df090"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_onehot = RNN_OneHot(vocab_size, 128, vocab_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_onehot.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in loader_onehot:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_onehot(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader_onehot):.4f}\")\n",
        "\n",
        "print(\"Training Time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjXhkOw40IZH",
        "outputId": "2b24c08c-6f20-4f76-e1e0-74ffcf079432"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-76012416.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  x = torch.tensor(x, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.2620\n",
            "Epoch 2, Loss: 6.4237\n",
            "Epoch 3, Loss: 5.6981\n",
            "Epoch 4, Loss: 4.8330\n",
            "Epoch 5, Loss: 3.9335\n",
            "Epoch 6, Loss: 3.0739\n",
            "Epoch 7, Loss: 2.3182\n",
            "Epoch 8, Loss: 1.6850\n",
            "Epoch 9, Loss: 1.2027\n",
            "Epoch 10, Loss: 0.8552\n",
            "Training Time: 1231.505687236786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_onehot(model, start_text, length=20):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words[-sequence_length:]\n",
        "        x = [one_hot_encode(word, vocab_size) for word in seq]\n",
        "        x = torch.tensor([x], dtype=torch.float32).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            predicted = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        next_word = idx2word[predicted]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(generate_text_onehot(model_onehot, \"the night was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_decrudZ0IWt",
        "outputId": "70c3681a-c93d-47a5-db2a-7fefba84e9ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the night was the trapper than sail and air in the sun and the a tree in the hot that if the boat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IndexedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "        x = torch.tensor([word2idx[word] for word in seq], dtype=torch.long)\n",
        "        y = torch.tensor(word2idx[target], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "dataset_embed = IndexedDataset(sequences)\n",
        "loader_embed = torch.utils.data.DataLoader(dataset_embed, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "BSp8Xf0d0IS4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super(RNN_Embedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "H_OlJucT0IQf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_embed = RNN_Embedding(vocab_size, 100, 128).to(device)\n",
        "optimizer = optim.Adam(model_embed.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in loader_embed:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_embed(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader_embed):.4f}\")\n",
        "\n",
        "print(\"Training Time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqnxHlLV0rR5",
        "outputId": "6cc40d15-0f63-4f69-fa15-fffbeccfa0cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.3314\n",
            "Epoch 2, Loss: 6.4323\n",
            "Epoch 3, Loss: 5.8943\n",
            "Epoch 4, Loss: 5.3598\n",
            "Epoch 5, Loss: 4.8228\n",
            "Epoch 6, Loss: 4.2934\n",
            "Epoch 7, Loss: 3.7779\n",
            "Epoch 8, Loss: 3.2983\n",
            "Epoch 9, Loss: 2.8672\n",
            "Epoch 10, Loss: 2.4866\n",
            "Training Time: 11.806597232818604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_embedding(model, start_text, length=20):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words[-sequence_length:]\n",
        "        x = torch.tensor([[word2idx[word] for word in seq]], dtype=torch.long).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            predicted = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        next_word = idx2word[predicted]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(generate_text_embedding(model_embed, \"the night was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og5X3YMu0rKh",
        "outputId": "c4fdc1f2-b460-40be-b587-1953ce922a11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the night was all the night-tide, of destruction, with the sky, and the dusk. of the moon and stars? list to the yarn,\n"
          ]
        }
      ]
    }
  ]
}